{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":104884,"sourceType":"datasetVersion","datasetId":54339}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport tensorflow as tf\nimport shap\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import ResNet50, EfficientNetB0\nfrom tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Concatenate, Input, Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.utils import to_categorical\nimport keras.backend as K\nfrom skimage import exposure\nfrom sklearn.model_selection import train_test_split\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-04T18:11:52.609514Z","iopub.execute_input":"2025-04-04T18:11:52.609746Z","iopub.status.idle":"2025-04-04T18:12:06.387796Z","shell.execute_reply.started":"2025-04-04T18:11:52.609725Z","shell.execute_reply":"2025-04-04T18:12:06.387077Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"#Load Dataset & Metadata\nDATA_PATH = \"../input/skin-cancer-mnist-ham10000/\"\nIMAGE_PATHS = [DATA_PATH + \"HAM10000_images_part_1/\", DATA_PATH + \"HAM10000_images_part_2/\"]\nCSV_PATH = DATA_PATH + \"HAM10000_metadata.csv\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T18:12:33.148485Z","iopub.execute_input":"2025-04-04T18:12:33.149147Z","iopub.status.idle":"2025-04-04T18:12:33.153190Z","shell.execute_reply.started":"2025-04-04T18:12:33.149106Z","shell.execute_reply":"2025-04-04T18:12:33.152192Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Load metadata CSV\ndf = pd.read_csv(CSV_PATH)\n# Debugging: Check column names\nprint(\"CSV Columns:\", df.columns)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T18:12:47.933482Z","iopub.execute_input":"2025-04-04T18:12:47.933842Z","iopub.status.idle":"2025-04-04T18:12:47.967024Z","shell.execute_reply.started":"2025-04-04T18:12:47.933811Z","shell.execute_reply":"2025-04-04T18:12:47.966106Z"}},"outputs":[{"name":"stdout","text":"CSV Columns: Index(['lesion_id', 'image_id', 'dx', 'dx_type', 'age', 'sex', 'localization'], dtype='object')\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"#  Ensure 'dx' (diagnosis) column exists\nif 'dx' not in df.columns:\n    raise KeyError(\"Column 'dx' not found in metadata CSV!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T18:12:50.424477Z","iopub.execute_input":"2025-04-04T18:12:50.424783Z","iopub.status.idle":"2025-04-04T18:12:50.432053Z","shell.execute_reply.started":"2025-04-04T18:12:50.424759Z","shell.execute_reply":"2025-04-04T18:12:50.431115Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"#  Map Lesion Types to Numeric Labels\nlesion_types = {label: idx for idx, label in enumerate(df['dx'].unique())}\ndf['label'] = df['dx'].map(lesion_types)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T18:12:53.190075Z","iopub.execute_input":"2025-04-04T18:12:53.190455Z","iopub.status.idle":"2025-04-04T18:12:53.203544Z","shell.execute_reply.started":"2025-04-04T18:12:53.190412Z","shell.execute_reply":"2025-04-04T18:12:53.202624Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"#  Function to Get Image Path\ndef get_image_path(img_id):\n    for path in IMAGE_PATHS:\n        img_path = os.path.join(path, img_id + \".jpg\")\n        if os.path.exists(img_path):\n            return img_path\n    return None\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T18:12:59.288959Z","iopub.execute_input":"2025-04-04T18:12:59.289317Z","iopub.status.idle":"2025-04-04T18:12:59.293854Z","shell.execute_reply.started":"2025-04-04T18:12:59.289278Z","shell.execute_reply":"2025-04-04T18:12:59.292738Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"#  Preprocess Images\ndef preprocess_image(img_id):\n    img_path = get_image_path(img_id)\n    if img_path is None:\n        return np.zeros((224, 224, 3))  # Placeholder for missing images\n    img = cv2.imread(img_path)\n    img = cv2.resize(img, (224, 224))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img / 255.0  # Normalize\n    return img\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T18:13:02.449070Z","iopub.execute_input":"2025-04-04T18:13:02.449407Z","iopub.status.idle":"2025-04-04T18:13:02.454176Z","shell.execute_reply.started":"2025-04-04T18:13:02.449379Z","shell.execute_reply":"2025-04-04T18:13:02.453142Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"#  Load Images & Labels\nimages = np.array([preprocess_image(img_id) for img_id in df['image_id']])\nlabels = to_categorical(df['label'].values, num_classes=7)  # One-hot encoding\n\n# Debugging: Check shapes\nprint(f\"Images Shape: {images.shape}, Labels Shape: {labels.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T18:13:08.542582Z","iopub.execute_input":"2025-04-04T18:13:08.542918Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#  Split Data (80% Train, 20% Validation)\ntrain_images, val_images, train_labels, val_labels = train_test_split(\n    images, labels, test_size=0.2, random_state=42\n)\nprint(f\"Training Data: {train_images.shape}, {train_labels.shape}\")\nprint(f\"Validation Data: {val_images.shape}, {val_labels.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T18:08:17.705268Z","iopub.execute_input":"2025-04-04T18:08:17.705622Z","iopub.status.idle":"2025-04-04T18:08:23.530567Z","shell.execute_reply.started":"2025-04-04T18:08:17.705590Z","shell.execute_reply":"2025-04-04T18:08:23.529521Z"}},"outputs":[{"name":"stdout","text":"Training Data: (8012, 224, 224, 3), (8012, 7)\nValidation Data: (2003, 224, 224, 3), (2003, 7)\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# 1. Define dual_input_generator function\ndef dual_input_generator(generator):\n    while True:\n        x, y = next(generator)  # Get the images and labels\n        yield [x, x], y  # Yield the same image for both inputs\n\n# 2. Create the data augmentation generator\ndata_gen = ImageDataGenerator(\n    rotation_range=30,\n    horizontal_flip=True,\n    brightness_range=[0.8, 1.2],\n    zoom_range=0.2\n)\n\n# 3. Create base generator using the data augmentation\nbase_generator = data_gen.flow(train_images, train_labels, batch_size=32)\n\n# 4. Wrap the base generator to yield dual inputs\ntrain_generator = dual_input_generator(base_generator)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T18:11:31.752628Z","iopub.execute_input":"2025-04-04T18:11:31.753041Z","execution_failed":"2025-04-04T18:11:35.231Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#  Build Deep Learning Model\nresnet = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\nefficientnet = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T18:08:58.177673Z","iopub.execute_input":"2025-04-04T18:08:58.178017Z","iopub.status.idle":"2025-04-04T18:09:00.266045Z","shell.execute_reply.started":"2025-04-04T18:08:58.177984Z","shell.execute_reply":"2025-04-04T18:09:00.265088Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# Freeze pretrained layers\nfor layer in resnet.layers:\n    layer.trainable = False\nfor layer in efficientnet.layers:\n    layer.trainable = False\n    \n# Feature extraction\nx1 = GlobalAveragePooling2D()(resnet.output)\nx2 = GlobalAveragePooling2D()(efficientnet.output)\n\n# Attention Mechanism for Feature Fusion\ndef attention_layer(input_tensor):\n    attention_probs = Dense(tf.keras.backend.int_shape(input_tensor)[-1], activation='softmax')(input_tensor)\n    return input_tensor * attention_probs\n\n# Attention-enhanced features\nx1 = attention_layer(x1)\nx2 = attention_layer(x2)\n\n# Merge features\nfused = Concatenate()([x1, x2])\nfused = Dropout(0.5)(fused)\nfused = Dense(128, activation='relu')(fused)\noutput = Dense(7, activation='softmax')(fused)  # Apply the layer to get tensor\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T18:09:03.140839Z","iopub.execute_input":"2025-04-04T18:09:03.141153Z","iopub.status.idle":"2025-04-04T18:09:03.185192Z","shell.execute_reply.started":"2025-04-04T18:09:03.141130Z","shell.execute_reply":"2025-04-04T18:09:03.184420Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Define Model\nmodel = Model(inputs=[resnet.input, efficientnet.input], outputs=output)\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T18:09:11.057484Z","iopub.execute_input":"2025-04-04T18:09:11.057827Z","iopub.status.idle":"2025-04-04T18:09:11.086647Z","shell.execute_reply.started":"2025-04-04T18:09:11.057797Z","shell.execute_reply":"2025-04-04T18:09:11.085960Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# Step 5: Fit the model using the dual input generator\nmodel.fit(\n    train_generator,\n    steps_per_epoch=len(train_images) // 32,  # Number of steps per epoch\n    epochs=10,\n    validation_data=([val_images, val_images], val_labels)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T18:09:14.133909Z","iopub.execute_input":"2025-04-04T18:09:14.134207Z","iopub.status.idle":"2025-04-04T18:09:14.967013Z","shell.execute_reply.started":"2025-04-04T18:09:14.134183Z","shell.execute_reply":"2025-04-04T18:09:14.965837Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-b264a45a2b80>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Step 5: Fit the model using the dual input generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Number of steps per epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/from_generator_op.py\u001b[0m in \u001b[0;36m_from_generator\u001b[0;34m(generator, output_types, output_shapes, args, output_signature, name)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mspec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTypeSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         raise TypeError(f\"`output_signature` must contain objects that are \"\n\u001b[0m\u001b[1;32m    125\u001b[0m                         \u001b[0;34mf\"subclass of `tf.TypeSpec` but found {type(spec)} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                         f\"which is not.\")\n","\u001b[0;31mTypeError\u001b[0m: `output_signature` must contain objects that are subclass of `tf.TypeSpec` but found <class 'list'> which is not."],"ename":"TypeError","evalue":"`output_signature` must contain objects that are subclass of `tf.TypeSpec` but found <class 'list'> which is not.","output_type":"error"}],"execution_count":25},{"cell_type":"code","source":"print(df.columns)\n# Load metadata\nCSV_PATH = \"../input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv\"\ndf = pd.read_csv(CSV_PATH)\n\n# Debugging: Print available columns\nprint(df.columns)\n\n# Check if 'dx' column exists (diagnosis)\nif 'dx' in df.columns:\n    lesion_types = {label: idx for idx, label in enumerate(df['dx'].unique())}\n    df['label'] = df['dx'].map(lesion_types)  # Create the label column\nelse:\n    raise KeyError(\"Column 'dx' not found in CSV file!\")\n\n# Print the first few rows\nprint(df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T08:54:47.961858Z","iopub.execute_input":"2025-04-04T08:54:47.962269Z","iopub.status.idle":"2025-04-04T08:54:48.043481Z","shell.execute_reply.started":"2025-04-04T08:54:47.962242Z","shell.execute_reply":"2025-04-04T08:54:48.042505Z"}},"outputs":[{"name":"stdout","text":"Index(['lesion_id', 'image_id', 'dx', 'dx_type', 'age', 'sex', 'localization'], dtype='object')\nIndex(['lesion_id', 'image_id', 'dx', 'dx_type', 'age', 'sex', 'localization'], dtype='object')\n     lesion_id      image_id   dx dx_type   age   sex localization  label\n0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp      0\n1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp      0\n2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp      0\n3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp      0\n4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear      0\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Load images & labels\nimages = np.array([preprocess_image(img_id) for img_id in df['image_id']])\nlabels = to_categorical(df['label'].values, num_classes=7)  # One-hot encoding","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T08:55:00.496131Z","iopub.execute_input":"2025-04-04T08:55:00.496456Z","execution_failed":"2025-04-04T08:56:48.994Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split into training and validation sets\nfrom sklearn.model_selection import train_test_split\ntrain_images, val_images, train_labels, val_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T08:46:29.173445Z","iopub.execute_input":"2025-04-04T08:46:29.173812Z","iopub.status.idle":"2025-04-04T08:46:31.863477Z","shell.execute_reply.started":"2025-04-04T08:46:29.173787Z","shell.execute_reply":"2025-04-04T08:46:31.862087Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-9cc421406e6a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Split into training and validation sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"],"ename":"NameError","evalue":"name 'images' is not defined","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}